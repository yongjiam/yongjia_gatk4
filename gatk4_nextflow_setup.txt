## guide on how to run nextflow pipepline using different solutions
## get nextflow required scripts and files
git clone https://gencore.bio.nyu.edu/variant-calling-pipeline-gatk4/
>>> prepare ref genome database
## index genome fasta for bwa mapping
srun --export=all -n 1 -c 10 bwa index genome_database/genome.fasta

## create picard dictionary
PJAR=/scratch/pawsey0399/yjia/tools/miniconda3/envs/nf-env/share/picard-2.18.29-0/picard.jar
srun --export=all -n 1 -c 10 java -jar $PJAR CreateSequenceDictionary R=RGT_V1.fasta O=RGT_V1.dict

## prepare snpEff database
wget https://snpeff.blob.core.windows.net/versions/snpEff_latest_core.zip ## Download latest version
get reference genome fasta sequence file (xxx.fa/xxx.fa.gz) to ./genomes
get gff3 file (xxx.gff3/xxx.gff3.gz) to ./xxx/genes.gff3 or genes.gff3.gz
copy cds.fa protein.fa to ./xxx/cds.fa protein.fa

echo "xxx.genome : xxx" >> snpEff.config ## add to config file

java -jar snpEff.jar build -gff3 -v CDC_scaffold1511 ## build database
java -jar snpEff.jar dump CDC_scaffold1511 | less  ## check database

>>Solution 1: use conda to install all required tools and packages
Need to install:
    Nextflow: require version 22.10.x, which requires downgrading other packages
    GATK4
    BWA
    Picard Tools
    Samtools
    SnpEff
    R (dependency for some GATK steps, need to find out all required R packages)
key notes:
  --install tools in a new conda environment
  --after installing picard and snpeff, need to find out the jar files and define PICARD_JAR and SNPEFF_JAR variables
  --go to the dockerfile to find out what R packages are needed 
  --or run R in docker images to find installed packages and install them manually in conda R environment
      In R: 
      installed <- as.data.frame(installed.packages())
      isntalled$Package
      write.csv(installed, 'installed_previously.csv')
      installedPreviously <- read.csv('installed_previously.csv')
      install.packages(installedPreviously$Package)
    --in main.nf, command:
        java -jar $SNPEFF_JAR -v      -dataDir /data/shunlin/nextflow_output/snpeff_data      RGT_split       Barley-P1_S60_L001_filtered_snps_2.vcf > Barley-P1_S60_L001_filtered_snps.ann.vcf
        remove -dataDir (the data_dir was defined in snpeff.config file, defaul as ./data; set dataDir will overide that set in config file, also try to avoid set -c new.config, for unknown reason this             does not work)

In setonix Run: 
export SNPEFF_JAR=/scratch/pawsey0399/yjia/tools/snpEff/snpEff.jar
export PICARD_JAR=/scratch/pawsey0399/yjia/tools/miniconda3/envs/nf-env/share/picard-2.18.29-0/picard.jar

NFILE=/scratch/pawsey0399/yjia/tools/variant-calling-pipeline-gatk4/main3.nf
CONFIG=/scratch/pawsey0399/yjia/tools/variant-calling-pipeline-gatk4/nextflow3.config

srun --export=all -n 1 -c 128  nextflow run main3.nf -c nextflow3.config

##### save working conda environment and install elsewhere
conda activate <environment_name>
conda env export > environment.yaml
conda env create -f environment.yaml
conda activate <environment_name>

>>Solution 2: use docker image
cd to where Dockerfile
vi Dockerfile, add --no-cerificate to wget command
docker build -t yongjia_gatk4 .
docker images
Run: nextflow run main.nf -c nextflow.config -with-docker yongjia_gatk4

## save and share local docker image
docker save yongjia_gatk4 > yongjia_gatk4.tar
## publish docker image to docker hub repository
    ## login to my docker hub account
    docker login
    ## add a tag to my images to under my docker hub user name
    docker tag yongjia_gatk4:latest yongjia111/yongjia_gatk4:latest
    ## push my local images to docker hub
    docker push yongjia111/yongjia_gatk4:latest
    ## pull from docker hub
    docker push yongjia111/yongjia_gatk4:latest

>>Solution 3; use singularity
## run directly from public docker images
singularity run docker://yongjia111/yongjia_gatk4 gatk ## test
Run: srun --export=all -n 1 -c 128  nextflow run main.nf -c nextflow.config -with-singularity docker://yongjia111/yongjia_gatk4

## build singularity image locally from public docker image
singularity pull docker://yongjia111/yongjia_gatk4 ## create yongjia_gatk4_latest.sif file
or from local docker image
sudo singularity build yongjia_gatk4.sif docker://yongjia_gatk4:latest
Run: srun --export=all -n 1 -c 128  nextflow run main.nf -c nextflow.config -with-singularity yongjia_gatk4_latest.sif

or:
set singularity container in nextflow.config file:
        process.container = "yongjia111/yongjia_gatk4:latest"
        singularity.enabled = true
        singularity.autoMounts = true ## need to put all data into PWD where nextflow launched, and also chmod to give full permission (chmod not working, not able to create gatktemp dir)
Run: srun --export=all -n 1 -c 128  nextflow run main.nf -c nextflow.config -with-singularity
